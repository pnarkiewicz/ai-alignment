Truthful - 10:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 128
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon-ipo
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: False
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_10
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 9:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 128
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_9
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 8:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 128
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: False
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_8
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 7:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 128
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon-ipo
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_7
    dataset:
        dataset_type: truthful
        split_type: train
GSM8k - 2:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/gsm8k.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 256
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon-ipo
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            increase_rounds: True
            multiturn: True
            max_num_rounds: 3
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/gsm_2
    dataset:
        dataset_type: gsm8k
        split_type: train
GSM8k - 1:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/gsm8k.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 256
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            increase_rounds: True
            multiturn: True
            max_num_rounds: 3
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/gsm_1
    dataset:
        dataset_type: gsm8k
        split_type: train
GSM8k - 0:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/gsm8k.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            increase_rounds: True
            multiturn: True
            max_num_rounds: 3
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/gsm_0
    dataset:
        dataset_type: gsm8k
        split_type: train
Truthful - 6:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon-ipo
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
            increase_rounds: True
            multiturn: True
            max_num_rounds: 3
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_6
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 5:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
            increase_rounds: True
            multiturn: True
            max_num_rounds: 3
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_5
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 4:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 256
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_4
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 3:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_3
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 2:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: False
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_2
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 1:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon-ipo
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: True
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_1
    dataset:
        dataset_type: truthful
        split_type: train
Truthful - 0:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 52
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: paged_adamw_32bit
        learning_rate: 3e-5
        max_grad_norm: 0.0003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        opening_speeches_only: True
        supplemental:
            max_new_tokens: 32
            epoch_size: 16
            save_steps: 10
            reward_type: prob
            loss_type: bon-ipo
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            self_play: False
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/truthful_0
    dataset:
        dataset_type: truthful
        split_type: train
Local Train - GSM8k:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct # download from https://huggingface.co/delphi-suite/v0-llama2-100k
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/gsm8k.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 20
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: adamw_torch # (no bits and bytes locally)
        learning_rate: 2e-4
        max_grad_norm: 0.1
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 512
        opening_speeches_only: True
        supplemental:
            epoch_size: 4   # num examples used per step
            save_steps: 4
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
            increase_rounds: True
            multiturn: True
            max_num_rounds: 3
    logging_and_saving_config:
        logging_steps: 5
        output_dir: checkpoints/test_gsm8k
    dataset:
        dataset_type: gsm8k
        split_type: train
Local Train - Truthful:
    model_name: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-3B-Instruct
    target: debater
    llm_type: llama
    max_length: 4096
    prompt_config:
        file_path: prompts/configs/truthful.yaml
        default_prompt_name: Debate Prompt
        use_hardcoded_topics: False
        hardcoded_topic_config: null
    training_hyperparameters:
        steps: 21
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: adamw_torch # (no bits and bytes locally)
        learning_rate: 3e-5
        max_grad_norm: 0.003
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 256
        opening_speeches_only: True
        supplemental:
            epoch_size: 32
            save_steps: 4
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: hf_wrapper
            judge_model: /net/pr2/projects/plgrid/plggaialignment/plgpikaminski/hf_models/Llama-3.2-1B-Instruct
            baseline: True
    logging_and_saving_config:
        logging_steps: 4
        output_dir: checkpoints/exp0
    dataset:
        dataset_type: truthful
        split_type: train
Local Train:
    model_name: checkpoints/v0-llama2-100k # download from https://huggingface.co/delphi-suite/v0-llama2-100k 
    target: debater
    llm_type: llama
    max_length: 2048
    training_hyperparameters:
        steps: 20
        num_train_epochs: 1
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 1
        optim: adamw_torch # (no bits and bytes locally)
        learning_rate: 2e-4
        max_grad_norm: 0.1
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        target_module: all
        lora_rank: 32
        supplemental:
            max_new_tokens: 32
            epoch_size: 4   # num examples used per step
            save_steps: 4
            reward_type: prob
            loss_type: bon
            multiplier: 7
            judge_type: arbitrary_attribute
            judge_feature: "l"
            evaluate: false
    logging_and_saving_config:
        logging_steps: 5
        output_dir: checkpoints/path/to/save/model
    dataset:
        dataset_type: quality
        split_type: train
Test - Consultancy:
    model_name: stub_model
    target: debater
    llm_type: stub_llm
    speech_structure: default_consultancy
    training_hyperparameters:
        num_train_epochs: 2
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 10e-6
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /fake/file/path
    dataset:
        dataset_type: judge_preferences
        full_dataset_file_path: 2024-03-15_16:08:55.960902
Test:
    model_name: stub_model
    target: debater
    llm_type: stub_llm
    training_hyperparameters:
        num_train_epochs: 2
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 2e-6
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /fake/file/path
    dataset:
        dataset_type: judge_preferences
        full_dataset_file_path: 2024-03-11_00:19:01.230232
Test - Iterative:
    model_name: stub_model
    target: debater
    llm_type: stub_llm
    training_hyperparameters:
        num_train_epochs: 2
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 2e-6
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /fake/file/path
    dataset:
        dataset_type: quality
Iterative - Experiment:
    model_name: /vast/spa9663/models/trained_models/llama-3-mega-merged
    target: debater
    llm_type: llama3
    opening_speeches_only: True
    training_hyperparameters:
        num_train_epochs: 2
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 10e-5
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
        steps: 1
        supplemental:
            epoch_size: 1024
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /vast/spa9663/models/trained_models/llama-3-DPO-611-bon-test
    dataset:
        dataset_type: quality
        split_type: train
Mixtral:
    model_name: /vast/spa9663/models/trained_models/mixtral-8x7b-unified-merged
    target: debater
    llm_type: mistral
    training_hyperparameters:
        num_train_epochs: 4
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 10e-5
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /vast/spa9663/models/trained_models/mixtral-8x7b-dpo-326
    dataset:
        dataset_type: judge_preferences
        full_dataset_file_path: 2024-03-11_00:19:01.230232
Mixtral - Consultant:
    model_name: /vast/spa9663/models/trained_models/mixtral-8x7b-unified-merged
    target: debater
    llm_type: mistral
    speech_structure: default_consultancy
    training_hyperparameters:
        num_train_epochs: 4
        per_device_train_batch_size: 1
        gradient_accumulation_steps: 8
        optim: paged_adamw_32bit
        learning_rate: 10e-5
        max_grad_norm: 0.3
        warmup_ratio: 0.03
        lr_scheduler_type: constant
        peft_type: lora
    logging_and_saving_config:
        logging_steps: 1
        output_dir: /vast/spa9663/models/trained_models/mixtral-8x7b-dpo-41-consultant
    dataset:
        dataset_type: judge_preferences
        full_dataset_file_path: 2024-03-15_16:08:55.960902
